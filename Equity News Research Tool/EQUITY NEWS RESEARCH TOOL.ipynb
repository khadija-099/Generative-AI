{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c7f5a04",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "15aa8410",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import streamlit as st\n",
    "import pickle\n",
    "import time\n",
    "import langchain\n",
    "from langchain import OpenAI\n",
    "from langchain.chains import RetrievalQAWithSourcesChain\n",
    "from langchain.chains.qa_with_sources.loading import load_qa_with_sources_chain\n",
    "from langchain.document_loaders import UnstructuredURLLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "81f0ca09",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "04e7fccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "af5b94fb",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for OpenAI\n  Value error, Did not find openai_api_key, please add an environment variable `OPENAI_API_KEY` which contains it, or pass `openai_api_key` as a named parameter. [type=value_error, input_value={'openai_api_key': None, ...ne, 'http_client': None}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.9/v/value_error",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m llm \u001b[38;5;241m=\u001b[39m OpenAI(openai_api_key \u001b[38;5;241m=\u001b[39m api_key, temperature \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.9\u001b[39m, max_tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m500\u001b[39m)\n",
      "File \u001b[1;32mC:\\Anaconda\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:213\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.finalize.<locals>.warn_if_direct_instance\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    211\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    212\u001b[0m     emit_warning()\n\u001b[1;32m--> 213\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\Anaconda\\Lib\\site-packages\\langchain_core\\load\\serializable.py:111\u001b[0m, in \u001b[0;36mSerializable.__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    110\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\"\"\"\u001b[39;00m\n\u001b[1;32m--> 111\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\Anaconda\\Lib\\site-packages\\pydantic\\main.py:209\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[1;34m(self, **data)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[39;00m\n\u001b[0;32m    208\u001b[0m __tracebackhide__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 209\u001b[0m validated_self \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__pydantic_validator__\u001b[38;5;241m.\u001b[39mvalidate_python(data, self_instance\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m validated_self:\n\u001b[0;32m    211\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    212\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA custom validator is returning a value other than `self`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    213\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReturning anything other than `self` from a top level model validator isn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt supported when validating via `__init__`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    214\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSee the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    215\u001b[0m         category\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    216\u001b[0m     )\n",
      "\u001b[1;31mValidationError\u001b[0m: 1 validation error for OpenAI\n  Value error, Did not find openai_api_key, please add an environment variable `OPENAI_API_KEY` which contains it, or pass `openai_api_key` as a named parameter. [type=value_error, input_value={'openai_api_key': None, ...ne, 'http_client': None}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.9/v/value_error"
     ]
    }
   ],
   "source": [
    "llm = OpenAI(openai_api_key = api_key, temperature = 0.9, max_tokens = 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fea9db1",
   "metadata": {},
   "source": [
    "# loading the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3ecc5098",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaders = UnstructuredURLLoader(urls = [\"https://www.moneycontrol.com/news/business/markets/wall-street-rises-as-tesla-soars-on-ai-optimism-11351111.html\",\n",
    "                                        \"https://www.moneycontrol.com/news/business/tata-motors-launches-punch-icng-price-starts-at-rs-7-1-lakh-11098751.html\"\n",
    "])\n",
    "data = loaders.load()\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6aa548b",
   "metadata": {},
   "source": [
    "# Splitting The Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "48c1c54d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size= 500,\n",
    "    chunk_overlap = 100\n",
    ")\n",
    "docs = text_splitter.split_documents(data)\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5a192947",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'https://www.moneycontrol.com/news/business/markets/wall-street-rises-as-tesla-soars-on-ai-optimism-11351111.html'}, page_content='Reuters\\n\\nSeptember 12, 2023 / 06:56 IST\\n\\nWall Street rises as Tesla soars on AI optimism\\n\\nThe Nasdaq closed sharply higher on Monday as Tesla surged on optimism around artificial intelligence and investors awaited inflation data due later this week.\\n\\nTeslaÃ‚ (TSLA.O)Ã‚ rallied 10% after Morgan StanleyÃ‚ upgradedÃ‚ the electric car maker to \"overweight\" from \"equal-weight,\" saying its Dojo supercomputer could boost the company\\'s market value by nearly $600 billion.')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b264693e",
   "metadata": {},
   "source": [
    "# Creating OpenAI Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0bea6b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217fbb30",
   "metadata": {},
   "source": [
    "# Creating Database(FAISS VECTOR INDEX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d075ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorindex_openai = FAISS.from_documents(docs, embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30399b08",
   "metadata": {},
   "source": [
    "# Storing VectorIndex into Local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b6e42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"vector_index.pkl\", 'wb') as f:\n",
    "    pickle.dump(vectorindex_openai , f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a03fec8",
   "metadata": {},
   "source": [
    "# Loading .pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12197b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"vector_index.pkl\", \"rb\") as f:\n",
    "    vectorIndex = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500de776",
   "metadata": {},
   "source": [
    "# Creating RetrievalQAWithSourcesChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82eba53",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = RetrievalQAWithSourcesChain.from_llm(llm = llm, retriever = vectorIndex.as_retriever())\n",
    "chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73813001",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is the price of Tiago iCNG?\"\n",
    "langchain.debug = True\n",
    "chain({'question': query, return_only_outputs=True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a129e66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d1de88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db36658d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f3eb34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42ab5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in pycharm:\n",
    "#requirements.txt & main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0fb46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "main.py\n",
    "\n",
    "llm = OpenAI(temperature = 0.9, max_tokens = 500)\n",
    "import os\n",
    "import streamlit as st\n",
    "import pickle\n",
    "import time\n",
    "import langchain\n",
    "from langchain.document_loaders import UnstructuredURLLoader\n",
    "from langchain.chains import RetrievalQAWithSourcesChain\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from dotenv import load_dotenv\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccae66c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8f3430",
   "metadata": {},
   "outputs": [],
   "source": [
    "st.title(\"News Research Tool ðŸ“ˆ\")\n",
    "st.sidebar.title(\"News Article Urls\")\n",
    "\n",
    "urls = []\n",
    "for i in range(3):\n",
    "    url = st.sidebar.text_input(f\"{URL} {i+1}\")\n",
    "    urls.append(url)\n",
    "    \n",
    "process_url_clicked = st.sidebar.button(\"Process URL\")\n",
    "\n",
    "\n",
    "file_path = \"faiss_store_openai.pkl\"\n",
    "main_placeholder = st.empty()\n",
    "if process_url_clicked:\n",
    "    #load data\n",
    "    loader = UnstructuredURLLoader(url = urls)\n",
    "    data = loader.load()\n",
    "    main_placeholder.text(\"Data Loading........Started......âœ…âœ…âœ…\")\n",
    "    #split data\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        separators = [\"/n/n\",\"/n\",\",\",\".\"], \n",
    "        chunk_size = 500\n",
    "    )\n",
    "    main_placeholder.text(\"TextSplitter.......Started.........âœ…âœ…âœ…\")\n",
    "    docs = text_splitter.split_document(data)\n",
    "    #create embeddings\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "    vectorstore_openai = FAISS.from_documents(docs, embeddings)\n",
    "    main_placeholder = st.text(\"Embedding Vector Started Building......âœ…âœ…âœ…\")\n",
    "    time.sleep(2)\n",
    "    \n",
    "    #save this vectorindex file into pickle file\n",
    "    with ope(\"file_path\",\"wb\") as f:\n",
    "        pickle.dump(vectorstore_openai, f)\n",
    "        \n",
    "        \n",
    "        \n",
    "query = main_placeholder.text_input(\"Question: \")\n",
    "if query:\n",
    "    if os.file_path.exists(file_path):\n",
    "        with open(file_path, \"rb\") as f:\n",
    "            vectorstore = pickle.load(f)\n",
    "            chain = RetrievalQAWithSourcesChain.from_llm(llm = llm, retriever = vectorstore.as_retriever())\n",
    "            result = chain({\"Question\": query}, return_only_output = True)\n",
    "            st.header(\"Answer\")\n",
    "            # {\"answer\": \"\", \"sources\": \"\"}\n",
    "            st.write(result[\"answer\"])\n",
    "            \n",
    "            \n",
    "            #display sources if available\n",
    "            sources = result.get(\"sources\", \"\")\n",
    "            if sources:\n",
    "                st.subheader(\"Sources:\")\n",
    "                sources_list = sources.split(\"\\n\")\n",
    "                for source in sources_list:\n",
    "                    st.write(source)\n",
    "            \n",
    "            \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8342b55a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad78268",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae410f69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56080f93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
